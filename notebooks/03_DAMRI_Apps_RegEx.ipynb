{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "a56c7908",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "3eda7876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokenized_raw_text</th>\n",
       "      <th>tokenized_preprocessed_text</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>gabisa beli tiket jir</td>\n",
       "      <td>gabisa beli tiket jir</td>\n",
       "      <td>['gabisa', 'beli', 'tiket', 'jir']</td>\n",
       "      <td>['gabisa', 'beli', 'tiket', 'jir']</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5.2</td>\n",
       "      <td>2025-09-04 11:13:20</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>good banget,simple dengan pemesanan tiket via ...</td>\n",
       "      <td>good bangetsimple mesan tiket via aplikasi adm...</td>\n",
       "      <td>['good', 'bangetsimple', 'dengan', 'pemesanan'...</td>\n",
       "      <td>['good', 'bangetsimple', 'mesan', 'tiket', 'vi...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5.2</td>\n",
       "      <td>2025-09-03 06:31:04</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mau ngecek ongkir kirim paket ga tersedia.. pa...</td>\n",
       "      <td>mau ngecek ongkir kirim paket tidak sedia pada...</td>\n",
       "      <td>['mau', 'ngecek', 'ongkir', 'kirim', 'paket', ...</td>\n",
       "      <td>['mau', 'ngecek', 'ongkir', 'kirim', 'paket', ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5.2</td>\n",
       "      <td>2025-09-02 17:06:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nyaman banget naik bus damri dari jagakarsa ke...</td>\n",
       "      <td>nyaman banget naik bus damri jagakarsa airport...</td>\n",
       "      <td>['nyaman', 'banget', 'naik', 'bus', 'damri', '...</td>\n",
       "      <td>['nyaman', 'banget', 'naik', 'bus', 'damri', '...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5.1</td>\n",
       "      <td>2025-09-02 07:13:14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ini kenapa nik saya gk bisa buat daftar</td>\n",
       "      <td>kenapa nik tidak buat daftar</td>\n",
       "      <td>['ini', 'kenapa', 'nik', 'saya', 'gk', 'bisa',...</td>\n",
       "      <td>['kenapa', 'nik', 'tidak', 'buat', 'daftar']</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-08-31 07:00:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0                              gabisa beli tiket jir   \n",
       "1  good banget,simple dengan pemesanan tiket via ...   \n",
       "2  mau ngecek ongkir kirim paket ga tersedia.. pa...   \n",
       "3  nyaman banget naik bus damri dari jagakarsa ke...   \n",
       "4            ini kenapa nik saya gk bisa buat daftar   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0                              gabisa beli tiket jir   \n",
       "1  good bangetsimple mesan tiket via aplikasi adm...   \n",
       "2  mau ngecek ongkir kirim paket tidak sedia pada...   \n",
       "3  nyaman banget naik bus damri jagakarsa airport...   \n",
       "4                       kenapa nik tidak buat daftar   \n",
       "\n",
       "                                  tokenized_raw_text  \\\n",
       "0                 ['gabisa', 'beli', 'tiket', 'jir']   \n",
       "1  ['good', 'bangetsimple', 'dengan', 'pemesanan'...   \n",
       "2  ['mau', 'ngecek', 'ongkir', 'kirim', 'paket', ...   \n",
       "3  ['nyaman', 'banget', 'naik', 'bus', 'damri', '...   \n",
       "4  ['ini', 'kenapa', 'nik', 'saya', 'gk', 'bisa',...   \n",
       "\n",
       "                         tokenized_preprocessed_text  score  thumbsUpCount  \\\n",
       "0                 ['gabisa', 'beli', 'tiket', 'jir']      1              0   \n",
       "1  ['good', 'bangetsimple', 'mesan', 'tiket', 'vi...      5              0   \n",
       "2  ['mau', 'ngecek', 'ongkir', 'kirim', 'paket', ...      1              0   \n",
       "3  ['nyaman', 'banget', 'naik', 'bus', 'damri', '...      5              0   \n",
       "4       ['kenapa', 'nik', 'tidak', 'buat', 'daftar']      3              0   \n",
       "\n",
       "  reviewCreatedVersion                   at replyContent repliedAt  \n",
       "0                4.5.2  2025-09-04 11:13:20          NaN       NaN  \n",
       "1                4.5.2  2025-09-03 06:31:04          NaN       NaN  \n",
       "2                4.5.2  2025-09-02 17:06:03          NaN       NaN  \n",
       "3                4.5.1  2025-09-02 07:13:14          NaN       NaN  \n",
       "4                  NaN  2025-08-31 07:00:03          NaN       NaN  "
      ]
     },
     "execution_count": 252,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_damri = pd.read_csv('../data/damri_apps_preprocessed.csv')\n",
    "df_damri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "90a80c1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damri['cleaned_text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203b9bdc",
   "metadata": {},
   "source": [
    "### Word 'bantu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "725c67fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bantu = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6802f776",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\b\\w*bantu\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_bantu.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "2819a2d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bantu'}"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bantu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "db3ac830",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to clean the word bantu\n",
    "# change membantu to bantu\n",
    "\n",
    "def membantu_to_bantu(text):\n",
    "    return re.sub(r'(m(a|e)(m|n)bantu|ngebantu|bantu)(l|u*)', 'bantu', text)\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(membantu_to_bantu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2d6d0761",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sepaarte bantu to its own word\n",
    "def separate_bantu(text):\n",
    "    separated = re.sub(r'bantu', ' bantu ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_bantu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1de208d0",
   "metadata": {},
   "source": [
    "### Word aplikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "3f6f865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_aplikasi = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fef3fd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'(\\b\\w*aplikasi\\w*\\b)'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_aplikasi.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "45147e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'aplikasi'}"
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_aplikasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "49470d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean aplikasi\n",
    "def clean_aplikasi(text):\n",
    "    return re.sub('aplikasi\\w{0,2}\\s', 'aplikasi ', text)\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(clean_aplikasi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "620b88e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate aplikasi\n",
    "def separate_aplikasi(text):\n",
    "    separated = re.sub(r'aplikasi', ' aplikasi ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_aplikasi)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff6190ad",
   "metadata": {},
   "source": [
    "### Word 'damri'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "5003ddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_damri = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "fde14450",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\b\\w*damri\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_damri.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "dae9ce7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'damri'}"
      ]
     },
     "execution_count": 266,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_damri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "824e638a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate damri\n",
    "def separate_damri(text):\n",
    "    separated = re.sub(r'damri', ' damri ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_damri)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e30a92",
   "metadata": {},
   "source": [
    "### Word daftar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "1f431880",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_daftar = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "2270fded",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\b\\w*daftar\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_daftar.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "a75cdf8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'daftar'}"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_daftar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "f238dc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change men-, ter to base\n",
    "def clean_daftar(text):\n",
    "    return re.sub(r'(m(a|e)(m|n)daftar|terdaftar|ndaftar|daftar)(in)?', 'daftar', text)\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(clean_daftar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "39c56604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate daftar\n",
    "def separate_daftar(text):\n",
    "    separated = re.sub(r'daftar', ' daftar ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_daftar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad05917d",
   "metadata": {},
   "source": [
    "### Word 'bayar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "a17ee630",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_bayar = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "a82ae1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\b\\w*bayar\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_bayar.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "3515943c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bayar'}"
      ]
     },
     "execution_count": 275,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_bayar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "7328c26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change pembayaran to bayar\n",
    "def change_bayar(text):\n",
    "    return re.sub(\"pe?mbayara?n\", \"bayar\", text)\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(change_bayar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "d6f40ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate bayar\n",
    "def separate_bayar(text):\n",
    "    separated = re.sub(r'bayar', ' bayar ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_bayar)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d02b61",
   "metadata": {},
   "source": [
    "### Word 'tiket'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "3a77322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_tiket = set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "0124a68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = r'\\b\\w*tiket\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_tiket.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "4480312c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tiket'}"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tiket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "f2b333e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean tiket\n",
    "def clean_tiket(text):\n",
    "    result = re.sub(\"\\s\\w{0,2}tiket\\w{0,2}\\s\", \" tiket \", \" \"+text+\" \")\n",
    "    result = re.sub(r'\\s+', ' ', result)\n",
    "    return result\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(clean_tiket)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "44bd1871",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate tiket\n",
    "def separate_tiket(text):\n",
    "    separated = re.sub(r'tiket', ' tiket ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_tiket)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5327d29e",
   "metadata": {},
   "source": [
    "### word 'susah'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "0be85b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_susah = set()\n",
    "pattern = r'\\b\\w*su?sah\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_susah.update(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "eba2f08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'susah'}"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_susah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "27ac38d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate susah\n",
    "def separate_susah(text):\n",
    "    separated = re.sub(r'susah', ' susah ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_susah)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29542b03",
   "metadata": {},
   "source": [
    "### word 'pakai'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "5c36cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_pakai = set()\n",
    "pattern = r'\\b\\w*(?:make(?!t)|makai|pakai|pake(?!t))\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_pakai.update(matches)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "59cbfa4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pakai'}"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_pakai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "8007c646",
   "metadata": {},
   "outputs": [],
   "source": [
    "### change to pakai\n",
    "def change_pakai(text):\n",
    "    new_text = re.sub(r'make(?!t)|makai|pakai|pake(?!t)', 'pakai', text)\n",
    "    return new_text\n",
    "\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(change_pakai)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "68a61ff6",
   "metadata": {},
   "outputs": [],
   "source": [
    "### separate pakai\n",
    "def separate_pakai(text):\n",
    "    separated = re.sub(r'pakai', ' pakai ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_pakai)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9c5eda",
   "metadata": {},
   "source": [
    "### word 'rute'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "b51a85f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_rute = set()\n",
    "pattern = r'\\b\\w*rute\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_rute.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "874e4aa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rute'}"
      ]
     },
     "execution_count": 291,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_rute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d27656a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate rute\n",
    "def separate_rute(text):\n",
    "    separated = re.sub(r'rute', ' rute ', text)\n",
    "    separated = re.sub(r'\\s+', ' ', separated)  # Remove extra spaces\n",
    "    return separated.strip()\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(separate_rute)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b16d8ac",
   "metadata": {},
   "source": [
    "### word 'kecewa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "6ff592dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_kecewa = set()\n",
    "pattern = r'\\b\\w*(?:k?ecewa)\\w*\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_kecewa.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "f54d9d61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'kecewa'}"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_kecewa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "8daec61b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change to kecewa\n",
    "def change_kecewa(text):\n",
    "    new_text = re.sub(pattern, \"kecewa\", text)\n",
    "    new_text = re.sub(r'\\s+', ' ', new_text)\n",
    "    return new_text\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(change_kecewa)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee34293a",
   "metadata": {},
   "source": [
    "### word 'nya', 'yg', 'aja'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "6dc778d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_nya_yg_aja = set()\n",
    "pattern = r'\\b(yg|aja|nya)\\b'\n",
    "\n",
    "for text in df_damri['cleaned_text']:\n",
    "    matches = re.findall(pattern, text)\n",
    "    all_nya_yg_aja.update(matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "37c89763",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "set()"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_nya_yg_aja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "34749db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove\n",
    "def remove_word_nya_yg_aja(text):\n",
    "    new_text = re.sub(pattern, \"\", text)\n",
    "    new_text = re.sub(r'\\s+', ' ', new_text)\n",
    "    return new_text\n",
    "\n",
    "df_damri['cleaned_text'] = df_damri['cleaned_text'].apply(remove_word_nya_yg_aja)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742ce0f9",
   "metadata": {},
   "source": [
    "### to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4d3b3b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damri.to_csv('../data/damri_apps_preprocessed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
