{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad8db9f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/fadhinotgr/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "import pandas as pd\n",
    "from Sastrawi.Stemmer import StemmerFactory\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73c08264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>tokenized_raw_text</th>\n",
       "      <th>tokenized_preprocessed_text</th>\n",
       "      <th>score</th>\n",
       "      <th>thumbsUpCount</th>\n",
       "      <th>reviewCreatedVersion</th>\n",
       "      <th>at</th>\n",
       "      <th>replyContent</th>\n",
       "      <th>repliedAt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bug/ keamanan ? aplikasi lama ga di buka ketik...</td>\n",
       "      <td>bug aman aplikasi lama tidak buka mau buka sel...</td>\n",
       "      <td>['bug', 'keamanan', 'aplikasi', 'lama', 'ga', ...</td>\n",
       "      <td>['bug', 'aman', 'aplikasi', 'lama', 'tidak', '...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5.4</td>\n",
       "      <td>2025-09-19 20:37:03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Armada sangat sedikit butuh waktu yg lama untu...</td>\n",
       "      <td>armada sangat sedikit butuh waktu lama tunggu ...</td>\n",
       "      <td>['armada', 'sangat', 'sedikit', 'butuh', 'wakt...</td>\n",
       "      <td>['armada', 'sangat', 'sedikit', 'butuh', 'wakt...</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-18 19:32:01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sangat membantu,,bisa pilih kursi tanpa harus ...</td>\n",
       "      <td>sangat bantu bisa pilih kursi harus pergi loket</td>\n",
       "      <td>['sangat', 'membantubisa', 'pilih', 'kursi', '...</td>\n",
       "      <td>['sangat', 'membantubisa', 'pilih', 'kursi', '...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-16 17:30:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pelayanannya baik</td>\n",
       "      <td>layan baik</td>\n",
       "      <td>['pelayanannya', 'baik']</td>\n",
       "      <td>['layan', 'baik']</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2025-09-16 15:38:28</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sangat membantu</td>\n",
       "      <td>sangat bantu</td>\n",
       "      <td>['sangat', 'membantu']</td>\n",
       "      <td>['sangat', 'bantu']</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>4.5.4</td>\n",
       "      <td>2025-09-15 15:31:35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content  \\\n",
       "0  bug/ keamanan ? aplikasi lama ga di buka ketik...   \n",
       "1  Armada sangat sedikit butuh waktu yg lama untu...   \n",
       "2  sangat membantu,,bisa pilih kursi tanpa harus ...   \n",
       "3                                  Pelayanannya baik   \n",
       "4                                    sangat membantu   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  bug aman aplikasi lama tidak buka mau buka sel...   \n",
       "1  armada sangat sedikit butuh waktu lama tunggu ...   \n",
       "2    sangat bantu bisa pilih kursi harus pergi loket   \n",
       "3                                         layan baik   \n",
       "4                                       sangat bantu   \n",
       "\n",
       "                                  tokenized_raw_text  \\\n",
       "0  ['bug', 'keamanan', 'aplikasi', 'lama', 'ga', ...   \n",
       "1  ['armada', 'sangat', 'sedikit', 'butuh', 'wakt...   \n",
       "2  ['sangat', 'membantubisa', 'pilih', 'kursi', '...   \n",
       "3                           ['pelayanannya', 'baik']   \n",
       "4                             ['sangat', 'membantu']   \n",
       "\n",
       "                         tokenized_preprocessed_text  score  thumbsUpCount  \\\n",
       "0  ['bug', 'aman', 'aplikasi', 'lama', 'tidak', '...      2              0   \n",
       "1  ['armada', 'sangat', 'sedikit', 'butuh', 'wakt...      2              0   \n",
       "2  ['sangat', 'membantubisa', 'pilih', 'kursi', '...      5              0   \n",
       "3                                  ['layan', 'baik']      5              0   \n",
       "4                                ['sangat', 'bantu']      5              0   \n",
       "\n",
       "  reviewCreatedVersion                   at replyContent repliedAt  \n",
       "0                4.5.4  2025-09-19 20:37:03          NaN       NaN  \n",
       "1                  NaN  2025-09-18 19:32:01          NaN       NaN  \n",
       "2                  NaN  2025-09-16 17:30:00          NaN       NaN  \n",
       "3                  NaN  2025-09-16 15:38:28          NaN       NaN  \n",
       "4                4.5.4  2025-09-15 15:31:35          NaN       NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load Data\n",
    "df_damri = pd.read_csv(\"../data/damri_apps_preprocessed.csv\")\n",
    "df_damri.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cca76cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for text in df_damri['tokenized_preprocessed_text']:\n",
    "    for word in text:\n",
    "        all_words.append(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "324569d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word Frequencies: Counter({\"'\": 89892, 'a': 43560, ',': 40145, ' ': 40145, 'i': 18938, 'n': 15628, 't': 14103, 's': 13134, 'e': 13108, 'k': 13060, 'u': 11932, 'l': 10462, 'r': 10348, 'm': 9598, 'd': 8469, 'g': 8338, 'p': 8011, 'b': 7933, 'o': 6175, 'h': 5589, '[': 4945, ']': 4945, 'y': 3549, 'j': 2577, 'c': 1709, 'w': 1151, 'f': 1020, 'v': 553, '2': 456, '0': 269, '1': 198, '3': 111, '5': 96, '4': 77, 'x': 65, '7': 48, 'z': 47, '9': 37, 'q': 34, '8': 32, '6': 29})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "word_frequencies = Counter(all_words)\n",
    "print(\"Word Frequencies:\", word_frequencies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a4231a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_words = sorted(word_frequencies.items(), key=lambda item: item[1], reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b3a7b1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word to Number Mapping (Sorted by Frequency): {\"'\": 1, 'a': 2, ',': 3, ' ': 4, 'i': 5, 'n': 6, 't': 7, 's': 8, 'e': 9, 'k': 10, 'u': 11, 'l': 12, 'r': 13, 'm': 14, 'd': 15, 'g': 16, 'p': 17, 'b': 18, 'o': 19, 'h': 20, '[': 21, ']': 22, 'y': 23, 'j': 24, 'c': 25, 'w': 26, 'f': 27, 'v': 28, '2': 29, '0': 30, '1': 31, '3': 32, '5': 33, '4': 34, 'x': 35, '7': 36, 'z': 37, '9': 38, 'q': 39, '8': 40, '6': 41}\n"
     ]
    }
   ],
   "source": [
    "word_to_number = {}\n",
    "for i, (word, frequency) in enumerate(sorted_words):\n",
    "    word_to_number[word] = i + 1  # Assign numbers starting from 1\n",
    "\n",
    "print(\"Word to Number Mapping (Sorted by Frequency):\", word_to_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3a8780c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_damri['cleaned_text'].fillna('', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e6f84a72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "independentFeatures = cv.fit_transform(df_damri['cleaned_text']).toarray()\n",
    "independentFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae81fd6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4945, 5083)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independentFeatures.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
